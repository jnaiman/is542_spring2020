# Step 1: Plot the distribution
speeds = seq(50, 130) # km/h
distribution = dnorm(speeds, mean=90, sd=10)
plot(speeds, distribution, type='l', xlab='Speed', ylab='Prob. distribution')
source('~/Downloads/plot_polygons.R') # to help wiht plotting
speeds = seq(50, 130) # km/h
distribution = dnorm(speeds, mean=90, sd=10)
plot(speeds, distribution, type='l', xlab='Speed', ylab='Prob. distribution')
# Step 2: Plot the measurement in question
#  First, we can draw a line
abline(v=100, col='blue')
# We can also use polygon to show the value > 100 km/hr in area
measurement = 100 # km/s & we know we want > than this value so:
x2 = seq(measurement, 130, length=100)
y2 = dnorm(x2, mean=90, sd=10) # y-values from dnorm
#polygon(c(measurement,x2,130),c(0,y2,0),col="red") # plots on top of previous plot by default
draw_polygon(x2, y2)
# Step 4: Calculate
# From the problem statement we see "probability" and "more than" this means this area
#  since total is normalized to 1
prob = pnorm(measurement, mean=90,sd=10)
print(prob) # we see this is ~84% which is going against our intuition -> gotta use lower.tail flag
prob = pnorm(measurement, mean=90,sd=10, lower.tail=FALSE)
print(prob)
# Normal problem 2:
# For a certain type of computers, the length of time between charges
#   of the battery is normally distributed with a mean of 50 hours and
#   a standard deviation of 15 hours. John owns one of these computers
#   and wants to know the probability that the length of time will be
#   between 50 and 70 hours.
# Step 1: Plot the distribution
chargingTime = seq(0, 100) # km/h
distribution = dnorm(chargingTime, mean=50, sd=15)
plot(chargingTime, distribution, type='l', xlab='Hours', ylab='Prob. distribution')
chargingTime = seq(0, 100) # km/h
distribution = dnorm(chargingTime, mean=50, sd=15)
plot(chargingTime, distribution, type='l', xlab='Hours', ylab='Prob. distribution')
# Step 2: Plot the measurement in question
abline(v=50, col='blue')
abline(v=70, col='blue')
# We can also use polygon to show between 50 & 70
measurement1 = 50
measurement2 = 70
x2 = seq(measurement1, measurement2, length=100)
y2 = dnorm(x2, mean=50, sd=15) # y-values from dnorm
draw_polygon(x2, y2)
#polygon(c(measurement1,x2,measurement2),c(0,y2,0),col="red") # plots on top of previous plot by default
# Step 4: Calculate
# From the problem statement we see "probability" and "more than" this means this area
#  since total is normalized to 1
# We'll need to subtract things to this:
prob1 = pnorm(measurement1, mean=50,sd=15)
prob2 = pnorm(measurement2, mean=50,sd=15)
print(prob2-prob1)
# Normal problem 3:
# Entry to a certain University is determined by a national test.
# The scores on this test are normally distributed with a mean of 500
# and a standard deviation of 100. Tom wants to be admitted to this
# university and he knows that he must score better than at least
# 70% of the students who took the test. Tom takes the test and
# scores 585. Will he be admitted to this university?
# Step 1: Plot the distribution
scores = seq(0, 1000)
distribution = dnorm(scores, mean=500, sd=100)
plot(scores, distribution, type='l', xlab='Test score', ylab='Prob. distribution')
Zscore70 = qnorm(0.70, mean=500, sd=100)
abline(v=Zscore70, col="blue")
#print(Zscore70) # we can see this is 552 < 585 so he should be admitted!
# let's keep plotting to make sure
abline(v=585, col="red")
legend("topright", c("70% score", "Tom's score"), col=c("blue","red"), lw=1)
print(Zscore70) # 552 < 585
# We can use the function "sample" to simulate
#  a fair coin toss
#help(sample)
nTosses = 10
samples = sample(2,size=nTosses, replace=TRUE) # replace=TRUE just means we start again with equal prob of heads/tails
#print(samples)
# now, lets re-map 1=>0 & 2=>1 just for consistency in using the binomial formula
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
prop_sample = sum(samples)/nTosses
print(prop_sample)
nTosses = 10
samples = sample(2,size=nTosses, replace=TRUE) # replace=TRUE just means we start again with equal prob of heads/tails
#print(samples)
# now, lets re-map 1=>0 & 2=>1 just for consistency in using the binomial formula
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
#print(samples)
# What do we expect the # of successes & failures to be?
# Well, for a fair coin it should be p=0.5
# What about for our sample above?
prop_sample = sum(samples)/nTosses
print(prop_sample)
nTosses = 10
samples = sample(2,size=nTosses, replace=TRUE) # replace=TRUE just means we start again with equal prob of heads/tails
#print(samples)
# now, lets re-map 1=>0 & 2=>1 just for consistency in using the binomial formula
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
#print(samples)
# What do we expect the # of successes & failures to be?
# Well, for a fair coin it should be p=0.5
# What about for our sample above?
prop_sample = sum(samples)/nTosses
print(prop_sample)
nTosses = 10
samples = sample(2,size=nTosses, replace=TRUE) # replace=TRUE just means we start again with equal prob of heads/tails
#print(samples)
# now, lets re-map 1=>0 & 2=>1 just for consistency in using the binomial formula
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
#print(samples)
# What do we expect the # of successes & failures to be?
# Well, for a fair coin it should be p=0.5
# What about for our sample above?
prop_sample = sum(samples)/nTosses
print(prop_sample)
nTosses = 10
samples = sample(2,size=nTosses, replace=TRUE) # replace=TRUE just means we start again with equal prob of heads/tails
#print(samples)
# now, lets re-map 1=>0 & 2=>1 just for consistency in using the binomial formula
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
#print(samples)
# What do we expect the # of successes & failures to be?
# Well, for a fair coin it should be p=0.5
# What about for our sample above?
prop_sample = sum(samples)/nTosses
print(prop_sample)
nTosses = 10
samples = sample(2,size=nTosses, replace=TRUE) # replace=TRUE just means we start again with equal prob of heads/tails
#print(samples)
# now, lets re-map 1=>0 & 2=>1 just for consistency in using the binomial formula
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
#print(samples)
# What do we expect the # of successes & failures to be?
# Well, for a fair coin it should be p=0.5
# What about for our sample above?
prop_sample = sum(samples)/nTosses
print(prop_sample)
# Let's simulate our coin throws again, and ask how likely is it that we get all tails for the
#  first 5 throws and a head only on the 6th throw?
# We can take a look at this:
nToss = 6
samples = sample(2,size=nToss, replace=TRUE)
# now, lets re-map 1=>0 & 2=>1 just for consistency w/the definitions of probability & success
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
print(samples) # **run this a few times**
# Let's simulate our coin throws again, and ask how likely is it that we get all tails for the
#  first 5 throws and a head only on the 6th throw?
# We can take a look at this:
nToss = 6
samples = sample(2,size=nToss, replace=TRUE)
# now, lets re-map 1=>0 & 2=>1 just for consistency w/the definitions of probability & success
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
print(samples) # **run this a few times**
# Let's simulate our coin throws again, and ask how likely is it that we get all tails for the
#  first 5 throws and a head only on the 6th throw?
# We can take a look at this:
nToss = 6
samples = sample(2,size=nToss, replace=TRUE)
# now, lets re-map 1=>0 & 2=>1 just for consistency w/the definitions of probability & success
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
print(samples) # **run this a few times**
# Let's simulate our coin throws again, and ask how likely is it that we get all tails for the
#  first 5 throws and a head only on the 6th throw?
# We can take a look at this:
nToss = 6
samples = sample(2,size=nToss, replace=TRUE)
# now, lets re-map 1=>0 & 2=>1 just for consistency w/the definitions of probability & success
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
print(samples) # **run this a few times**
samples = sample(2,size=nToss, replace=TRUE, prob=c(0.9, 1-0.9)) # prob=(SUCCESS, FAILURE)
#  Note: prob is for numbers (0, 1) so (fail, success)
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
# Q: Do you think I'll see more heads (1's) or tails (0's)?
#   **think on this for a minute before running**
print(samples) # **run this a few times**
samples = sample(2,size=nToss, replace=TRUE, prob=c(0.9, 1-0.9)) # prob=(SUCCESS, FAILURE)
#  Note: prob is for numbers (0, 1) so (fail, success)
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
# Q: Do you think I'll see more heads (1's) or tails (0's)?
#   **think on this for a minute before running**
print(samples) # **run this a few times**
samples = sample(2,size=nToss, replace=TRUE, prob=c(0.9, 1-0.9)) # prob=(SUCCESS, FAILURE)
#  Note: prob is for numbers (0, 1) so (fail, success)
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
# Q: Do you think I'll see more heads (1's) or tails (0's)?
#   **think on this for a minute before running**
print(samples) # **run this a few times**
samples = sample(2,size=nToss, replace=TRUE, prob=c(0.9, 1-0.9)) # prob=(SUCCESS, FAILURE)
#  Note: prob is for numbers (0, 1) so (fail, success)
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
# Q: Do you think I'll see more heads (1's) or tails (0's)?
#   **think on this for a minute before running**
print(samples) # **run this a few times**
samples = sample(2,size=nToss, replace=TRUE, prob=c(0.9, 1-0.9)) # prob=(SUCCESS, FAILURE)
#  Note: prob is for numbers (0, 1) so (fail, success)
samples[samples==1] = 0 # tails, failures
samples[samples==2] = 1 # heads, successes
# Q: Do you think I'll see more heads (1's) or tails (0's)?
#   **think on this for a minute before running**
print(samples) # **run this a few times**
# Infact, we can plot the theoretical distribution from what we know from our slides/OIS:
#    P(success on the nth trail, failure on n-1 trial) = (1-p)^(n-1) X p
# Let's first go back to a fair coin and set "p" to the probability of our fair coin toss:
p = 0.5
# Let's pick a number of trails to throw our dice:
nToss = 10
prob_suc_n_an = c()
nToss = 10 # toss coin nToss times
prob_suc_n_an = c()
# Now let's store, for each trial n, our calculated probability
#  of getting all failures and then a success on the nth coin flip
for (n in 1:nToss){
prob_suc_n_an = c(prob_suc_n_an, (1-p)^(n-1)*p)
}
# Let's make a bar plot for this:
barplot(prob_suc_n_an, names.arg=1:nToss, col='cyan',
xlab = 'N = Number of Trials',
ylab = 'Prob of getting 1st Success in Nth Trial')
# Let's compare to another unfair coin.
# First, I'll make some side-by-side plots, starting with our fair coin:
par(mfrow=c(1,2))
barplot(prob_suc_n_an, names.arg=1:nToss, col='cyan',
xlab = 'N = Number of Trials',
ylab = 'Prob of getting 1st Success in Nth Trial',
main="p=0.5")
# Now, let's assume I have an unfair coin that only gives heads 10% of the time:
p2 = 0.1
prob_suc_n_an2 = c()
for (n in 1:nToss){
prob_suc_n_an2 = c(prob_suc_n_an2, (1-p2)^(n-1)*p2)
}
barplot(prob_suc_n_an2, names.arg=1:nToss, col='magenta',
xlab = 'N = Number of Trials',
ylab = 'Prob of getting 1st Success in Nth Trial',
main='p=0.1')
# Let's say you are playing a game in which you want to roll a majority of 1's out of 6 sized die.
# So, if you have 10 rolls, you want to roll 5 or more ones let's see how likely this is.
# reset plot window
par(mfrow=c(1,1))
# Here, success is rolling a 1 - on a fair die this is simply 1 out of 6:
p = 1/6
#p = 0.9
# Lets start by having a game of 10 throws
nToss = 10
# What do we have to plot this?
help(dbinom)
k_suc = seq(0,nToss) # note: we can only have whole numbers
barplot(dbinom(k_suc,size=nToss, prob=p), width=1, names.arg=k_suc, col='magenta',
xlab = 'k successes - number of 1s',
ylab = 'Prob',
main='p=1/6; N=10',
space=0) # Note this space=0 is key to making our axis line up to our measurement!
# Lets plot our critera for winning - i.e. rolling 50% or more 1s.
#  In our game of 10 tosses, this is 5 or greater rolls of a 1.
abline(v=nToss*0.5+1, col='red', lw=2)
# Why +1 because we are starting our bars at 0 so we need to move 6 spaces!
# By eye we can see, the probability of >5 sucesses out of 10 throws is VERY small.
# We can even quantify this with:
print('Prob of majority of tosses being 1s = ')
print(1-pbinom(nToss*0.5, size=nToss, prob=p))
# note: 1- since we are looking for >, can also use "lower.tail" flip.
# Step 1: can we use the normal model?
n = 2500
p = 0.7
print(n*p)
print(n*(1-p))
# Both are > 10 so we are good to go!
# Step 2: Calculate mean and SD
normal_mean = n*p
normal_sd = (n*p*(1-p))**0.5
# Step 3: Use normal distribution to find this probability as a percentile
prob_norm = pnorm(1786,mean=normal_mean, sd=normal_sd, lower.tail=FALSE)
print(prob_norm)
help(pnorm)
# Note: we could have also just as easily used R to do the binomial calculation:
prob_binom = pbinom(1786, size=2500, prob=0.7, lower.tail=FALSE)
print(prob_binom)
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Downloads/plot_polygons.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
help(pnorm)
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
print(ZscoreTom)
#print(pnorm(ZscoreTom, ))
print(pnorm(ZscoreTom, mean=0, sd=1))
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
samples
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
samples
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
samples
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
help(sample)
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
help(pbinom)
source('~/Dropbox/teaching/stats_spring_2020/week06/inClass_week06_binomial.R')
