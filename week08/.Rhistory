install.packages(c("manipulate", "tigerstats"))
install.packages(c("car", "corrplot", "effects"))
par(mfrow=c(1,1))
# first, lets recall last week, our linear model for blood alcohol level vs. #
#  of beers drank
# read in data
BB <- read.csv("http://www.math.montana.edu/courses/s217/documents/beersbac.csv")
#print(BB)
# Script for class #9
# --------------------------
#   Basic Chi-squared things
# --------------------------
# lets start with our usual - plotting these distributions
x = seq(0, 50, length=200)
dist = dchisq(x, df=3)
plot(x, dist, type='l', ylab='Probability Distribution of Chi-Sq', xlab='Chi-Squared Value')
# ok, now lets loop through and plot a few different degrees of freedom
dfs = c(5, 10, 30)
# lets make them all different colors too
colors = c("red", "blue", "magenta")
for (i in 1:length(dfs)){
lines(x, dchisq(x,df=dfs[i]), col=colors[i])
}
# lets start with our usual - plotting these distributions for a few values
#  of the DOF parameter
x = seq(0, 50, length=200)
dist = dchisq(x, df=3)
plot(x, dist, type='l', ylab='Probability Distribution of Chi-Sq', xlab='Chi-Squared Value')
# ok, now lets loop through and plot a few different degrees of freedom
dfs = c(5, 10, 30)
# lets make them all different colors too
colors = c("red", "blue", "magenta")
for (i in 1:length(dfs)){
lines(x, dchisq(x,df=dfs[i]), col=colors[i])
}
# lets add another little legend for making things look nice
# making sure we include the first one
dfs = c(3, dfs) # append to dfs list
colors = c("black",colors) # append to colors list
legend("topright", as.character(dfs), col=colors, lwd=2)
lines(x, dnorm(x,mean=29,sd=7),col="green")
# now, lets say we have some made up distribution that has 8 DOF,
#and when we calculate our chi^2, we find a value of 10
#  what is the pvalue of this test statistic?
df = 8
test_stat = 10
x = seq(0, 50, length=200)
plot(x, dchisq(x, df=df), type='l', ylab='Probability Distribution of Chi-Sq', xlab='Chi-Squared Value')
# Turns out, just like for the normal & binomial distribution we can calculate percentages with a "p" function
pvalue = 1-pchisq(test_stat, df=df)
print(pvalue)
# also can do:
pvalue = pchisq(test_stat, df=df, lower.tail=FALSE)
print(pvalue)
# now lets plot what this corresponds to on our graph
x2=seq(test_stat,50,length=200)
y2=dchisq(x2,df=df)
# using our old friend and foe - the polygon function
#  *now* might be the last time we use it... maybe
polygon(c(test_stat,x2,0),c(0,y2,0),col="red")
# first lets make a vector holding each die roll
die_roll = c(1, 2, 3, 4, 5, 6)
# now lets plug in what Labby found for the observed rolls
# **COPY INTO WINDOW**
obs = c( 53222, 52118, 52465, 52338, 52244, 53285 )
# lets also fill in what we expect from theory
# recall
# first lets make a vector holding each die roll
die_roll = c(1, 2, 3, 4, 5, 6)
# now lets plug in what Labby found for the observed rolls
# **COPY INTO WINDOW**
obs = c( 53222, 52118, 52465, 52338, 52244, 53285 )
# lets also fill in what we expect from theory
# recall
number_of_dice_rolled_at_once = 12 # the number of die on the table
number_of_rolls = 26306 # How many rolls the machine did
# Let's calculate the expected value in each bin
expected_value_of_each_side = number_of_dice_rolled_at_once * number_of_rolls/6
# now, since this is true for all sides of the die we can
# for-loop over this
expected = c()
for (i in 1:6){
expected = c(expected,expected_value_of_each_side)
}
# Before we get to calculations, lets plot these results
barplot(obs, names.arg=die_roll)
# lets overplot what we expect from "theory"
abline(h=expected_value_of_each_side, col="blue")
# so we can see at the very top there, indeed it looks like
#  1  & 6 are more frequent then the others
# Let's zoom our plot a bit to check it out
barplot(obs, names.arg=die_roll, ylim=c(40000,60000))
abline(h=expected_value_of_each_side, col="blue")
# Let's zoom our plot a bit to check it out
barplot(obs, names.arg=die_roll, ylim=c(50000,55000))
abline(h=expected_value_of_each_side, col="blue")
# Now, lets calculate each element of the total chi squared test statistic:
# recall X^2 = sum( (observation-expected)^2/expected )
chi_vals = (obs - expected)**2/expected
#print(chi_vals)
test_stat_chi = sum(chi_vals)
print(test_stat_chi)
# now, we need to compare this to the appropriate chi-squared distribution
df = length(obs)-1
# print(df) = 5
pvalue = pchisq(test_stat_chi,df=df, lower.tail=F)
print(pvalue)
# just run this once
# also could be: library("poLCA", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
library("poLCA")
# load election data
data(election)
# **STOP HERE & SEE THAT EVERYBODY HAS THIS INSTALLED OK**
# lets look at a few variables in particular
#print(election$VOTE3)
#print(election$PARTY)
#print(election$EDUC)
#print(election$GENDER)
# now lets process the data a bit => turn numerical values into catagorical
election$VOTEF <- factor(election$VOTE3)
election$PARTY <- factor(election$PARTY)
election$EDUC <- factor(election$EDUC)
election$GENDER <- factor(election$GENDER)
# now, lets translate the different "levels" from 1, 2, NA to actual values
# look at help(election) to copy paste
#  also,posted on moodle
levels(election$VOTEF) <- c("Gore","Bush","Other")
levels(election$EDUC) <- c("<8th", "9-11 grades","HS Diploma", ">12 years schooling", "Junior College Degree", "BA/BS", "Adv. deg.")
levels(election$GENDER) <- c("Male", "Female")
levels(election$PARTY) <- c("Strong Democrat", "Weak Democrat", "Independent-Democrat", "Independent-Independent","Independent-Republican", "Weak Republican", "Strong Republican")
#require(ggplot2)
require(tabplot)
tableplot(election, select=c(VOTEF,PARTY,EDUC,GENDER),pals=list("BrBG"))
help(tableplot)
# anyway, lets though look at "full" datasets
#  i.e. data in which all answers are filled in
election2 <- na.omit(election[,c("VOTEF","PARTY","EDUC","GENDER")])
# note, we can sort things based on different columns
# ** play with this by changing sort=1 to other numbers!!!**
tableplot(election2, select=c(VOTEF,PARTY,EDUC,GENDER),sort=1,pals=list("BrBG"))
electable = table(election2$PARTY, election2$VOTEF)
print(electable)
print(chisq.test(electable)$expected)
print(chisq.test(electable))
# lets do another quick one: Is gender & who they voted for related
#H0: There is no relationship between gender (2 levels)
#    and voting results (Bush, Gore, Other) in the population.
#HA: There is a relationship between gender (2 levels)
#    and voting results (Bush, Gore, Other) in the population.
gentable = table(election2$VOTEF, election2$GENDER)
print(gentable)
print(chisq.test(gentable))
tableplot(election2, select=c(VOTEF,PARTY,EDUC,GENDER),sort=1,pals=list("BrBG"))
# We can aid our eyes by sorting by the gender column
tableplot(election2, select=c(VOTEF,PARTY,EDUC,GENDER),sort=4,pals=list("BrBG"))
# We can aid our eyes by sorting by the gender column
tableplot(election2, select=c(VOTEF,PARTY,EDUC,GENDER),sort=4,pals=list("BrBG"))
gentable = table(election2$VOTEF, election2$GENDER)
print(gentable)
print(chisq.test(gentable))
tableplot(election2, select=c(VOTEF,PARTY,EDUC,GENDER),sort=1,pals=list("BrBG"))
# We can aid our eyes by sorting by the gender column
tableplot(election2, select=c(VOTEF,PARTY,EDUC,GENDER),sort=2,pals=list("BrBG"))
# We can aid our eyes by sorting by the gender column
tableplot(election2, select=c(VOTEF,PARTY,EDUC,GENDER),sort=3,pals=list("BrBG"))
# We can aid our eyes by sorting by the gender column
tableplot(election2, select=c(VOTEF,PARTY,EDUC,GENDER),sort=4,pals=list("BrBG"))
install.packages("devtools")
# suppose a drug company has 3 formulations of a drug for pain relief for migranes
#  they randomly assign 1 of the 3 forumulations to 27 volunteers to take during
#  their next migrane episode & rate their pain levels from 1-10
# results look like:
drugA = c(4, 5, 4, 3, 2, 4, 3, 4, 4 )
drugB = c(6, 8, 4, 5, 4, 6, 5, 8, 6)
drugC = c(6, 7, 6, 6, 7, 5, 6, 5, 5)
boxplot(drugA, drugB, drugC, names=c("A", "B", "C"), xlab="Drug", ylab="Pain Scale")
# 2: Normality?
par(mfrow=c(1,3)) # for each drug
# drugA
qqnorm(drugA)
qqline(drugA)
# drugB
qqnorm(drugB)
qqline(drugB)
# drugC
qqnorm(drugC)
qqline(drugC)
# 3: similar variences?
print(var(drugA))
print(var(drugB))
print(var(drugC))
# 2: Normality?
par(mfrow=c(2,3)) # for each drug
hist(drugA)
# drugA
qqnorm(drugA)
qqline(drugA)
# drugB
qqnorm(drugB)
qqline(drugB)
# drugC
qqnorm(drugC)
qqline(drugC)
par(mfrow=c(2,3)) # for each drug - histograms and QQ-plots
# (i) hists
hist(drugA)
hist(drugB)
hist(drugC)
# (ii) qq plots
# drugA
qqnorm(drugA)
qqline(drugA)
# drugB
qqnorm(drugB)
qqline(drugB)
# drugC
qqnorm(drugC)
qqline(drugC)
pain = c(drugA,drugB,drugC)
drug = c(rep("A",9), rep("B",9), rep("C",9)) # just some fancy labeling
print(pain)
print(drug)
# we'll smoosh these together as a dataframe (like a pandas dataframe if you like python!)
migraine = data.frame(pain,drug)
print(migraine)
# now, if we remember back to some of our R excerizes:
# aov(response ~ factor, data=data_name)
# where here "response" responds to a "factor"
# i.e. the response is pain and the factor is the drug in our example
aov_results = aov(pain ~ drug, data=migraine)
print(aov_results)
# or for more info:
print('------')
print(summary(aov_results))
## NOTE: there are many ways to do this test, we are doing the defaults
print(pairwise.t.test(pain, drug, p.adjust="bonferroni"))
print(pairwise.t.test(pain, drug, p.adjust="bonferroni", alternative="greater"))
print(pairwise.t.test(pain, drug, p.adjust="bonferroni", alternative="greater"))
print(pairwise.t.test(pain, drug, p.adjust="bonferroni", alternative="less"))
par(mfrow=c(1,1))
# start by reading in data:
diet = read.csv("/Users/jillnaiman1/Dropbox/teaching/stats_spring_2019/lectures/week08/diet.csv",row.names=1)
# define a weight loss parameter
diet$weight.loss = diet$initial.weight - diet$final.weight
boxplot(weight.loss~diet.type,data=diet,col="light gray",
ylab = "Weight loss (kg)", xlab = "Diet type")
abline(h=0,col="blue")
# ANS2:
aov_results = aov(weight.loss ~ diet.type, data=diet)
summary(aov_results)
print(pairwise.t.test(diet$weight.loss, diet$diet.type, p.adjust="bonferroni"))
plot(x, dist, type='l', ylab = 'Prob. Dist. of Chi^2',
xlab='Chi^2 Value')
plot(x, dist, type='l', ylab = 'Prob. Dist. of Chi^2',
xlab='Chi^2 Value')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
help(pchisq)
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
obs
die_roll
expected
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
expected
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
x = seq(0, 50, length=200)
dist = dchisq(x, df=3)
plot(x, dist, type='l', ylab = 'Prob. Dist. of Chi^2',
xlab='Chi^2 Value', ylim = c(0, 0.3))
dfs = c(5, 10, 30)
colors = c("red", "blue", "magenta")
for (i in 1:length(dfs)){
lines(x, dchisq(x,df=dfs[i]), col=colors[i])
}
# adding in a legend to remind ourselves of what is what
# add in the black first df=3
dfs = c(3, dfs)
colors = c("black", colors)
legend("topright", as.character(dfs), col=colors, lw=2)
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
election$VOTEF
election$VOTE3
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
election$VOTEF
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
help(tableplot)
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_week09_chisqr.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
help(aov)
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
boxplot(drugA, drugB, drugC, names=c("A","B","C"),
xlab="Drug", ylab="Pain Scale")
help(pairwise.t.test)
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
source('~/Dropbox/teaching/stats_fall_2019/week09/inClass_anova_week09.R')
